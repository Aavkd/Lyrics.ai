# Flow-to-Lyrics Configuration
# =============================
# Copy this file to `.env` and adjust values as needed.
# All variables are optional and have sensible defaults.

# =============================================================================
# LLM CONFIGURATION (Ollama)
# =============================================================================

# Model name - change this to switch between different Ollama models
# Local examples: mistral:7b, llama3:8b, qwen2:7b, gemma2:9b
# Cloud examples: gemini-3-flash-preview:latest (requires API key)
OLLAMA_MODEL=ministral-3:8b

# Ollama API endpoint
# - For LOCAL Ollama:  http://localhost:11434
# - For CLOUD Ollama:  https://ollama.com
OLLAMA_URL=http://localhost:11434

# Generation temperature (0.0 = deterministic, 1.0 = maximum creativity)
OLLAMA_TEMPERATURE=0.7

# Request timeout in seconds
OLLAMA_TIMEOUT=600

# API key for cloud Ollama services (leave empty for local Ollama)
# Get your key from: https://ollama.com/settings/keys
# For local Ollama running on localhost, no API key is needed.
OLLAMA_API_KEY=

# =============================================================================
# AUDIO ENGINE
# =============================================================================

# Mock mode for development (skips Demucs vocal isolation)
MOCK_MODE=true

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

# API host and port
API_HOST=0.0.0.0
API_PORT=8000

# Maximum file upload size in MB
MAX_FILE_SIZE_MB=100
