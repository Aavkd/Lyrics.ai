# Flow-to-Lyrics Configuration
# =============================
# Copy this file to `.env` and adjust values as needed.
# All variables are optional and have sensible defaults.

# =============================================================================
# LLM CONFIGURATION (Ollama)
# =============================================================================

# Model name - change this to switch between different Ollama models
# Local examples: mistral:7b, llama3:8b, qwen2:7b, gemma2:9b
# Cloud examples: gemini-3-flash-preview:latest (requires API key)
OLLAMA_MODEL=ministral-3:8b

# Ollama API endpoint
# - For LOCAL Ollama:  http://localhost:11434
# - For CLOUD Ollama:  https://ollama.com
OLLAMA_URL=http://localhost:11434

# Generation temperature (0.0 = deterministic, 1.0 = maximum creativity)
OLLAMA_TEMPERATURE=0.7

# Request timeout in seconds
OLLAMA_TIMEOUT=600

# API key for cloud Ollama services (leave empty for local Ollama)
# Get your key from: https://ollama.com/settings/keys
# For local Ollama running on localhost, no API key is needed.
OLLAMA_API_KEY=

# =============================================================================
# AUDIO ENGINE
# =============================================================================

# Mock mode for development (skips Demucs vocal isolation)
MOCK_MODE=true

# Onset Detection Configuration
# These settings control syllable detection sensitivity

# Onset detection sensitivity threshold (default: 0.05)
# Lower = more sensitive (more syllables detected, may have false positives)
# Higher = less sensitive (fewer syllables, may miss some)
# Recommended range: 0.03 (very sensitive) to 0.15 (conservative)
ONSET_DELTA=0.05

# Enable energy-based onset detection (default: true)
# Combines spectral flux with energy peaks for more robust detection
ONSET_USE_ENERGY=true

# Maximum segment duration before automatic splitting (default: 1.0)
# Segments longer than this will be split at energy valleys
MAX_SEGMENT_DURATION=1.0

# Minimum frames between onsets (default: 1)
ONSET_WAIT=1

# =============================================================================
# PHONETIC ANALYSIS
# =============================================================================

# Phonetic recognition backend: "whisper" (recommended) or "allosaurus"
# - whisper: Better for mumbled/sung vocals (uses Whisper + g2p_en)
# - allosaurus: Universal phone recognizer (original, less accurate for vocals)
PHONETIC_MODEL=whisper

# Whisper model size (only used when PHONETIC_MODEL=whisper)
# Options: tiny (39MB), base (140MB), small (244MB), medium (769MB), large (2.9GB)
# Larger = more accurate but slower and uses more memory
WHISPER_MODEL_SIZE=base

# Full-audio transcription mode (default: true) - RECOMMENDED
# When true, transcribes entire audio once and aligns words to segments
# Much more accurate for short segments (<500ms) because Whisper has full context
# When false, uses per-segment transcription (legacy, less accurate)
WHISPER_USE_FULL_AUDIO=true

# Enable phonetic analysis (default: true)
PHONETIC_ENABLED=true

# Minimum segment duration for analysis in seconds (default: 0.10)
# Segments shorter than this won't be analyzed (Allosaurus needs context)
PHONETIC_MIN_DURATION=0.10

# Padding on each side of segment for context in seconds (default: 0.05)
# Adds acoustic context before/after each segment for better recognition
PHONETIC_PADDING=0.05

# Retry padding when first attempt fails in seconds (default: 0.10)
# Used when Allosaurus returns empty on first try
PHONETIC_RETRY_PADDING=0.10

# Enable vowel/consonant fallback when Allosaurus fails (default: true)
# Uses spectral features to classify as [vowel], [consonant], or [mid]
PHONETIC_FALLBACK_ENABLED=true

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

# API host and port
API_HOST=0.0.0.0
API_PORT=8000

# Maximum file upload size in MB
MAX_FILE_SIZE_MB=100
