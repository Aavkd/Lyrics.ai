# ðŸ“Š Flow-to-Lyrics: Project Status Report

**Generated**: 2025-12-27  
**Version**: MVP - English Only  
**Objective**: Transform informal vocal flows ("yaourt") into coherent rap/song lyrics with strict rhythmic precision and human validation.

---

## ðŸ“‹ Executive Summary

The Flow-to-Lyrics project is currently at approximately **55% completion** of the MVP roadmap from a **user perspective**. The **backend pipeline is now COMPLETE** with all 4 core engines working end-to-end:

1. âœ… **AudioEngine** - Analyzes audio, detects segments with stress/sustain
2. âœ… **PromptEngine** - Translates PivotJSON to LLM prompts
3. âœ… **GenerationEngine** - Generates candidates via Ollama (local or cloud)
4. âœ… **LyricValidator** - The "Gatekeeper" that filters by syllable count and groove score

The frontend remains a **read-only audio viewer** with no editing or generation capabilities.

### Current User Experience
Users can only:
1. **Import** an audio file (drag-and-drop)
2. **View** the waveform with auto-detected segments
3. **Play** the audio with spacebar control

**No editing, no lyric generation UI, no export.** The app is a visualization prototype. Lyric generation works via CLI only.

| Phase | Status | User-Facing? |
|-------|--------|--------------|
| Phase 0: Blind Test (Lyric Validation) | âœ… Complete | âŒ CLI only |
| Phase 1: Segmentation Tool | âš ï¸ Display only | âš ï¸ Read-only |
| Phase 2: End-to-End Integration | âš ï¸ Backend only | âŒ Not exposed |

---

## ðŸ”„ PRD Pipeline vs. Current Implementation

### Ã‰tape 1: Nettoyage & Isolation (Audio Pre-processing)

| Feature | PRD Requirement | Current State | Status |
|---------|-----------------|---------------|--------|
| Input formats | WAV/MP3 | MP3, WAV, M4A, FLAC, OGG âœ… | âœ… Done |
| Demucs v4 (Hybrid Transformer) | Required | Implemented with mock mode | âš ï¸ Partial |
| Vocal isolation | Separate vocals vs instrumental | Code exists but defaults to `MOCK_MODE=true` | âš ï¸ Partial |
| Mono 16kHz conversion | Required for optimal analysis | **Not implemented** | ðŸ”´ Missing |
| Normalized vocal stem | Required | **Not implemented** | ðŸ”´ Missing |

**Files Involved**:
- `audio_engine.py` â†’ `DemucsProcessor` class (lines 90-174)

**Notes**:
- Demucs processor is implemented but runs in mock mode by default
- Real Demucs processing requires GPU and is not tested in production
- No sample rate conversion or normalization step exists

---

### Ã‰tape 2: Extraction Structurelle & Validation UX

| Feature | PRD Requirement | Current State | Status |
|---------|-----------------|---------------|--------|
| Onset detection (Spectral Flux) | Librosa | âœ… Implemented via `librosa.onset.onset_detect()` | âœ… Done |
| Intensity/Stress detection | Amplitude peaks | âœ… Implemented via RMS amplitude analysis | âœ… Done |
| Interactive waveform | Wavesurfer.js + Regions | âœ… Fully functional | âœ… Done |
| Region drag/resize | Required | âœ… Implemented | âœ… Done |
| Merge/Split actions | Required | **Not implemented** | ðŸ”´ Missing |
| Delete regions | Required | **Not implemented** | ðŸ”´ Missing |
| Tap-to-Rhythm (Space key) | Manual marker placement | **Not implemented** | ðŸ”´ Missing |

**Files Involved**:
- `audio_engine.py` â†’ `LibrosaAnalyzer` class (lines 181-229)
- `frontend/components/AudioEditor.tsx` (526 lines)
- `frontend/components/SegmentList.tsx` (164 lines)

**Notes**:
- Onset detection works well (28 syllables detected in test audio)
- BPM detection has ~5% variance (123 vs 130 BPM actual)
| Sustained notes appear as single long segments instead of multiple syllables | âš ï¸ Known Issue |
| Stress pattern detection implemented | âœ… Done |

---

### Ã‰tape 3: Le JSON Pivot

| Feature | PRD Requirement | Current State | Status |
|---------|-----------------|---------------|--------|
| `meta.tempo` | Required | âœ… Implemented | âœ… Done |
| `meta.genre` | Required | **Not implemented** | ðŸ”´ Missing |
| `meta.theme` | Required | **Not implemented** | ðŸ”´ Missing |
| `meta.language` | Required (en-US) | **Not implemented** | ðŸ”´ Missing |
| `blocks[].id` | Required | âœ… Implemented | âœ… Done |
| `blocks[].rhyme_scheme` | Required | **Not implemented** | ðŸ”´ Missing |
| `blocks[].syllable_target` | Required | âœ… Implemented (auto-calculated) | âœ… Done |
| `segments[].time_start` | Required | âœ… Implemented | âœ… Done |
| `segments[].duration` | Required | âœ… Implemented | âœ… Done |
| `segments[].is_stressed` | Required | âœ… Implemented (dynamic detection) | âœ… Done |
| `segments[].is_sustained` | Required | âœ… Implemented (duration threshold) | âœ… Done |
| `segments[].pitch_contour` | Required | **Not implemented** | ðŸ”´ Missing |

**Current Output Structure**:
```json
{
  "meta": { "tempo": 123.05, "duration": 11.65 },
  "blocks": [{
    "id": 1,
    "syllable_target": 28,
    "segments": [
      { "time_start": 0.07, "duration": 0.186, "is_stressed": false }
    ]
  }],
  "_meta": { "filename": "test.mp3", "mock_mode": true }
}
```

**Files Involved**:
- `audio_engine.py` â†’ `PivotJSON`, `PivotFormatter` classes
- `frontend/store/useAudioStore.ts` â†’ TypeScript interfaces

---

### Ã‰tape 4: GÃ©nÃ©ration & Validation PhonÃ©tique

| Feature | PRD Requirement | Current State | Status |
|---------|-----------------|---------------|--------|
| "Generate Many, Filter Best" strategy | Required | âœ… Logic exists in `phase0_blind_test.py` | âœ… Done |
| g2p_en phonetic validation | Required | âœ… Fully implemented | âœ… Done |
| Syllable counting (auditory) | Required | âœ… Works correctly | âœ… Done |
| Stress pattern matching | Required | âœ… `LyricValidator.calculate_groove_score()` | âœ… Done |
| LLM integration (Local Ollama) | Required | âœ… `GenerationEngine` with ministral-3 | âœ… Done |
| Parallel 5-candidate generation | Required | âœ… Full pipeline: Prompt â†’ Ollama â†’ JSON parsing | âœ… Done |
| Syllabic scoring (0 or 1) | Required | âœ… `LyricValidator.validate_line()` | âœ… Done |
| Stress scoring (0.0 - 1.0) | Required | âœ… `LyricValidator` Groove Score (0.0-1.0) | âœ… Done |
| Retry with error-specific prompts | Required | **Not implemented** | ðŸ”´ Missing |
| **Prompt Engine (JSONâ†’Prompt)** | Required | âœ… `PromptEngine` class with external templates | âœ… Done |
| **Core Pipeline (Orchestrator)** | Required | âœ… `CorePipeline` class orchestrates all engines | âœ… Done |

**Files Involved**:
- `validator.py` â†’ `LyricValidator` class (The Gatekeeper - g2p_en phonetic validation)
- `core_pipeline.py` â†’ `CorePipeline` class (The Orchestrator - end-to-end flow)
- `generation_engine.py` â†’ `GenerationEngine` class (Ollama HTTP integration)
- `phase0_blind_test.py` â†’ `SyllableValidator`, `LyricGenerator` classes
- `prompt_engine.py` â†’ `PromptEngine` class (JSON-to-Prompt translation)
- `prompts/system_instruction.md` â†’ System prompt with persona and few-shot examples
- `prompts/user_template.md` â†’ User prompt template with placeholders
- `tests/test_generation.py` â†’ Test suite for GenerationEngine
- `tests/test_end_to_end.py` â†’ Test suite for Validator and CorePipeline

**Test Results** (Real LLM Generation - 2025-12-27):

| Step | Result | Details |
|------|--------|---------|
| Audio Analysis | âœ… | 7 syllables detected, pattern: DA-da-da-da-DA-da-da |
| LLM Generation | âœ… | 5 candidates from Ollama ministral-3 |
| Validation | âœ… | 3/5 matched syllable count |
| Best Match | âœ… | "No **way** to stop me, I **glide**" (score: 0.29) |

**Latest Pipeline Output:**
```
ðŸ§  Generated 5 candidates:
  1. "I **soar** the skies so free" (6 syllables âœ—)
  2. "No **way** to stop me, I **glide**" (7 syllables âœ“)
  3. "The **glow** of gold in my eyes" (7 syllables âœ“)
  4. "**Fly** fast, I'm wild in the night" (7 syllables âœ“)
  5. "**Go** hard, no one can hide" (6 syllables âœ—)

ðŸ† WINNING LYRIC: "No **way** to stop me, I **glide**"
ðŸ“Š GROOVE SCORE: 0.29
```

**Success Rate**: 60% (3/5 valid syllable matches)

---

### Ã‰tape 5: Alignement & Rendu

| Feature | PRD Requirement | Current State | Status |
|---------|-----------------|---------------|--------|
| CTC-Segmentation | Optional | **Not implemented** | ðŸ”´ Missing |
| Linear alignment | Alternative | **Not implemented** | ðŸ”´ Missing |
| Word-by-word text display | Required | **Not implemented** | ðŸ”´ Missing |
| Audio-text synchronization | Required | **Not implemented** | ðŸ”´ Missing |
| SSE streaming | Required | **Not implemented** | ðŸ”´ Missing |
| Export functionality | Required | **Not implemented** | ðŸ”´ Missing |

---

## ðŸ› ï¸ Technology Stack Comparison

### Backend (Python)

| Technology | PRD | Current | Status |
|------------|-----|---------|--------|
| FastAPI (Async, Websockets) | Required | âœ… FastAPI implemented | âš ï¸ No Websockets |
| Torchaudio | Required | Not used | ðŸ”´ Missing |
| Librosa | Required | âœ… Installed & used | âœ… Done |
| Demucs | Required | âœ… Installed (mock mode) | âš ï¸ Partial |
| g2p_en | Required | âœ… Fully functional | âœ… Done |
| nltk (CMU Dict) | Required | Not used directly | âš ï¸ Partial |
| Instructor/Outlines | Required for JSON | Regex-based parsing in GenerationEngine | âš ï¸ Alternative |
| Local Ollama (ministral-3) | Required | âœ… Fully integrated | âœ… Done |
| Cloud Ollama Support | Optional | âœ… API key authentication via `OLLAMA_API_KEY` | âœ… Done |

### Frontend (Next.js / React)

| Technology | PRD | Current | Status |
|------------|-----|---------|--------|
| Next.js 14 | Implied | âœ… Installed | âœ… Done |
| Wavesurfer.js v7 | Required | âœ… Fully integrated | âœ… Done |
| Regions Plugin | Required | âœ… Working | âœ… Done |
| Timeline Plugin | Required | **Not implemented** | ðŸ”´ Missing |
| Zustand | Required | âœ… Fully integrated | âœ… Done |
| SSE (Server-Sent Events) | Required | **Not implemented** | ðŸ”´ Missing |

---

## âœ… What The User Can Actually Do (Current UX)

Based on the current frontend interface, users can perform **3 core actions only**:

| Action | Works? | Notes |
|--------|--------|-------|
| ðŸŽµ **Import audio file** | âœ… | Drag-and-drop or click to select (MP3, WAV, etc.) |
| ðŸ‘ï¸ **View waveform + segments** | âœ… | See detected syllable regions overlaid on waveform |
| â–¶ï¸ **Play/pause audio** | âœ… | Button or Spacebar shortcut |

**That's it.** Everything else is either backend-only or code that exists but isn't exposed to the user.

### What Appears to Work But Doesn't

| Feature | Visual State | Reality |
|---------|--------------|---------|
| Drag/resize regions | Regions appear draggable | Changes aren't saved or exported |
| Segment table | Shows data | Read-only display, no editing |
| Zoom controls | Slider exists | Works but has no practical use |
| BPM display | Shows value | Informational only |

### Backend Infrastructure (Not User-Facing)
1. **FastAPI server** (`main.py`) - Runs on `localhost:8000`
2. **Audio upload endpoint** (`POST /upload`) - Returns Pivot JSON
3. **BPM/Onset detection** - Librosa analysis (~5% BPM variance)
4. **Phonetic syllable counting** - g2p_en works in `phase0_blind_test.py`
5. **Mock LLM generation** - Test script only, no API integration
6. **Prompt Engine** - `prompt_engine.py` translates PivotJSON to LLM prompts

---

## ðŸŽ¯ Target Frontend Experience (Missing vs Current)

The current frontend is a **temporary testing prototype** with poor UX ("trash" tier). The final implementation requires a complete overhaul to support true interactivity.

### 1. Interactivity Requirements (Currently Missing)
The user **IS NOT** currently able to effectively edit the segmentation. The target experience requires:
- [ ] **Drag & Resize**: Users must be able to freely move and resize segment regions.
- [ ] **Split & Merge**: Ability to cut a segment in two or join two segments.
- [ ] **Delete & Add**: Intuitive controls to remove false positives or add missing syllables.
- [ ] **Snap-to-Grid**: Segments should optionally snap to rhythm quantization.

### 2. Visual Requirements (Currently Basic)
The current waveform overlay is merely functional. The target design needs:
- [ ] **Distinct Blocks**: Regions should look like solid, interactive blocks that are **superposed directly onto the waveform** for easy edits.
- [ ] **Clear Handles**: Visual cues for resizing (left/right handles).
- [ ] **Hover Effects**: Clear visual feedback when hovering over editable zones.
- [ ] **Context Menus**: Right-click actions for specific segment operations.

> **Status**: The current UI exists purely to validate the backend data flow. A dedicated UI/UX phase is pending to build the actual editor.

---

## ðŸ”´ What Needs Refinement

### Critical (Blocks Core Functionality)
1. **Real LLM integration** - Currently mock only
3. **Tap-to-Rhythm feature** - Manual marker placement missing
4. **Region Split/Merge/Delete** - Editing actions missing
5. **End-to-end pipeline** - No connection between audio analysis and lyric generation

### Important (Affects Quality)
1. **BPM accuracy** - ~5% variance needs improvement
3. **Mono 16kHz conversion** - Missing audio preprocessing
4. **Stress pattern matching** - No scoring implemented
5. **Pitch contour detection** - Missing from Pivot JSON

### Nice to Have
1. **Timeline plugin** - Visual time markers
2. **SSE streaming** - Real-time lyric display
3. **Export functionality** - Save edited segments
4. **Genre/Theme metadata** - Not captured
5. **Multi-block support** - Only `blocks[0]` is rendered

---

## ðŸ“… Roadmap Progress

### Phase 0: "Blind Test" (Weeks 1-2) â†’ âœ… 100% Complete
- [x] Python script with syllable input
- [x] g2p_en phonetic validation
- [x] "Generate Many, Filter Best" logic
- [x] Prompt Engine (Step 2: JSON-to-Prompt translation)
- [x] Real LLM integration (Local Ollama with ministral-3)
- [x] Validator with Groove Score (0.0-1.0)
- [x] Core Pipeline orchestrating all engines

### Phase 1: Segmentation Tool (Weeks 3-4) â†’ âœ… 95% Complete
- [x] Wavesurfer.js frontend
- [x] Demucs backend (mock mode)
- [x] Audio â†’ Pivot JSON pipeline
- [x] Region visualization
- [x] Stress & Sustain detection (Enhanced Audio Analysis)
- [ ] Tap-to-Rhythm feature

### Phase 2: End-to-End Integration (Weeks 5-6) â†’ âš ï¸ 40% Complete
- [x] Connect Phase 0 + Phase 1 (via `core_pipeline.py`)
- [x] Full pipeline testing (8 tests passing)
- [ ] API endpoint for lyrics generation
- [ ] SSE streaming for lyrics
- [ ] Export functionality

---

## ðŸ“ Project Structure

```
Lyrics.ai/
â”œâ”€â”€ main.py                     # FastAPI server (215 lines)
â”œâ”€â”€ audio_engine.py             # Step 1: DSP logic - Demucs + Librosa (523 lines)
â”œâ”€â”€ prompt_engine.py            # Step 2: JSON-to-Prompt translation (270 lines)
â”œâ”€â”€ generation_engine.py        # Step 3: Ollama LLM integration (330 lines)
â”œâ”€â”€ validator.py                # Step 4: LyricValidator - The Gatekeeper (280 lines) â­ NEW
â”œâ”€â”€ core_pipeline.py            # Step 4: CorePipeline - The Orchestrator (267 lines) â­ NEW
â”œâ”€â”€ phase0_blind_test.py        # Original syllable validation script (362 lines)
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ test_audio_real.mp3         # Real test audio file
â”œâ”€â”€ prompts/                    # LLM prompt templates
â”‚   â”œâ”€â”€ system_instruction.md   # Persona + few-shot examples
â”‚   â””â”€â”€ user_template.md        # Jinja2-style user prompt
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_audio_analysis.py  # Step 1 tests
â”‚   â”œâ”€â”€ test_prompt_engine.py   # Step 2 tests
â”‚   â”œâ”€â”€ test_generation.py      # Step 3 tests (Ollama integration)
â”‚   â””â”€â”€ test_end_to_end.py      # Step 4 tests (Full pipeline) â­ NEW
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ prd.md                  # Product Requirements Document
â”‚   â”œâ”€â”€ PROJECT_STATUS.md       # This file
â”‚   â”œâ”€â”€ TECH_ROADMAP.md         # Technical roadmap
â”‚   â”œâ”€â”€ PHASE0_CHANGELOG.md     # Phase 0 changes
â”‚   â”œâ”€â”€ PHASE1_CHANGELOG.md     # Phase 1 changes
â”‚   â”œâ”€â”€ PHASE2_CHANGELOG.md     # Phase 2 changes
â”‚   â””â”€â”€ PHASE3_CHANGELOG.md     # Phase 3 changes (Validator + Pipeline) â­ NEW
â””â”€â”€ frontend/
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ page.tsx            # Main page layout
    â”‚   â”œâ”€â”€ layout.tsx          # Root layout
    â”‚   â””â”€â”€ globals.css         # Dark theme styles
    â”œâ”€â”€ components/
    â”‚   â”œâ”€â”€ AudioEditor.tsx     # Waveform editor (526 lines)
    â”‚   â””â”€â”€ SegmentList.tsx     # Segment table (164 lines)
    â”œâ”€â”€ store/
    â”‚   â””â”€â”€ useAudioStore.ts    # Zustand state (138 lines)
    â””â”€â”€ lib/
        â””â”€â”€ api.ts              # Backend API client (48 lines)
```

---

## ðŸš€ Recommended Next Steps

### Immediate (This Week)
1. **Implement real LLM integration** in `phase0_blind_test.py`
   - Add Groq API client
   - Replace mock `LyricGenerator` with real calls
   - Test >90% syllabic accuracy

2. **Refine Stress/Sustain Thresholds**
   - Tune `audio_engine.py` parameters based on real-world testing

### Short-term (Next 2 Weeks)
3. **Implement Tap-to-Rhythm** in `AudioEditor.tsx`
   - Add keyboard event listener for tap mode
   - Create new regions on tap
   - Sync with Zustand store

4. **Add Split/Merge/Delete actions**
   - Region context menu
   - Keyboard shortcuts

### Medium-term (Weeks 3-4)
5. **Connect Phase 0 + Phase 1**
   - New API endpoint for lyric generation
   - SSE streaming response
   - Frontend display component

6. **Export functionality**
   - Download edited Pivot JSON
   - Export as subtitle file (SRT/VTT)

---

## ðŸ§ª Known Issues

| Issue | Location | Severity | Notes |
|-------|----------|----------|-------|
| BPM variance ~5% | `LibrosaAnalyzer.analyze()` | Medium | May need prior estimation |
| Mock Demucs only | `DemucsProcessor` | Medium | Real processing needs GPU |
| Single block rendering | `AudioEditor.tsx` | Low | Only `blocks[0]` displayed |

---

*This document was auto-generated by analyzing the project codebase against the PRD specifications.*
